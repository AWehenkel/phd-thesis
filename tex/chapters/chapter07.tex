\null\vfill
{\centering
\parbox{\textwidth}{%
  \raggedright
  {%\itshape
  % \normal

   If I have seen further, it is by standing on shoulders of giants.\par\bigskip
  }
  \raggedleft\MakeUppercase{Isaac Newton}\par%
}}

\vfill\vfill

\chapter{Hybrid Generative Models}\label{ch:07}

\begin{chapter_outline}

We formalise hybrid learning within the probabilistic modelling framework and demonstrate that hybrid models exhibit greater generalisation capabilities than classical machine learning models.
Hybrid models reduce the misspecification of expert models with a machine learning (ML) component learned from data. We leverage the insight that the expert model is usually valid even outside the training domain to introduce a hybrid data augmentation strategy termed \textit{expert augmentation}. In contrast to many ML algorithms, the performance guarantees of hybrid models trained with expert augmentation are not limited to the training distribution. We validate the practical benefits of augmented hybrid models on a set of controlled experiments and reflect on the broader impact that hybrid learning may have shortly.

\end{chapter_outline}

\section{Prologue}
In this thesis, we have presented various algorithms to help practitioners build models from data. The last chapter has shown that effective inductive bias is necessary to learn models from medium- or high-dimensional data. Following the growing deployments of ML solutions into the real world and the related demand for performance guarantees throughout their lifetime, the ML research community has gained interest in out-of-distribution robustness. Machine learning algorithms are not anymore judged only on their ability to produce faithful models inside the training distribution but also on the behaviour of these models in out-of-distributions scenarios.

Although the concept of out-of-distribution robustness seems appealing, it does not clearly say what we are looking for. To use this concept rigorously, we argue that we shall first answer the following related question: $\bullet$~\textit{What is in-distribution?} $\bullet$~\textit{What is out-of-distribution?}  $\bullet$~\textit{What is the measure of robustness?} Refusing to answer one of these questions will inevitably lead to an ill-posed ML problem. It is essential to notice the distinction between out-of-distribution and not in-distribution. In practice, we might need to restrain ourselves to out-of-distribution settings that correspond to a well-defined subset of what is not in distribution. Finally, we shall be able to express robustness with a quantitative metric.

Hybrid models are the ones that explicitly combine expert models with a machine learning component. They constitute an excellent alternative to purely data-driven solutions and expert models that rely on assumptions often violated in practice. We expect that hybrid models require fewer data to achieve performance on par with ML models. They may also exhibit better interpretability. In addition, we argue that hybrid models are particularly well suited to work within the context of out-of-distribution robustness. Indeed, the expert model often depends on a low-dimensional set of parameters on which we can provide a rigorous definition of in-distribution and out-of-distribution.

In line with this argument, we propose an augmentation strategy based on the expert model that enforces a well-defined notion of robustness for a specific out-of-distribution scenario. We show that existing hybrid learning algorithms may learn effective representation but require an additional augmentation step to exhibit robustness. This chapter demonstrates that informed machine learning may achieve results that are out of reach for uninformed solutions. It also shows, once again, that combining various models may be beneficial.

% Nevertheless, recent results in image-to-text have defied this statement by combining large amounts of data with the effective inductive bias of modern deep learning techniques.
% - Limitation of classical machine learning algorithms is to be limited to the data they see. Inductive bias help going a bit beyond but is usually a weak form of prior knowledge that does not help much. In some setting it feels inneficient to try to learn everything from data. This is especially true in domains for which physics playa an important role.
%
% - A particular problem is the one of OOD data. That is if one of the marginal distribution is different. Explain why this may be a problem for general probabilistic models. In this case we need more than inductive bias. We need to understand what is the impact of distribution shift and to be able to make the model performance insensitive to it.
%
% - In the context of this thesis we have seen how relevant it can be to combine models. Now we push this even further by combining physics equations to depends on few parameters that provide a good high level explanation of  phenomenon but misses some lower effects and thus are innefective at doing a great prediction job in some setting. We combine with machine learning models to improve they predicition capabilities. We finally show that such hybrid models exhibits strong generalization performance outside from the training data with respects to shift that can be modeled accuratly by the physical equation.

\section{Robust Hybrid Learning With Expert Augmentation}

\subsection{Author contributions}
I co-authored this paper during an internship at Apple within the Health AI team led by Guillermo Sapiro. Hsu Hiang initially explored the idea of combining expert models with machine learning under the advisory of Jens Behrmann and J{\"o}rn-Henrik Jacobsen. I took over Hsu's work and, together with Jens and J{\"o}rn, we explored a probabilistic formulation of hybrid modelling and out-of-distribution robustness. We designed the experiments together, and I wrote the code corresponding to the two hybrid modelling frameworks (APHYNITY and the hybrid-VAE) used in this project. Gilles helped write the paper and design additional experiments to check the robustness of the expert augmentation in different settings. Guillermo gave feedback on the manuscript. Finally, Gilles, Jens, and J{\"o}rn gave feedback on the manuscript and helped me improve its writing.

\subsection{Reading tips}
The methods explored in the paper are specific to hybrid learning and have not been described in the background. Thus we encourage the reader to carefuly review the complete paper.

\includepdf[pages=-]{papers/Hybrid_learning_preprint.pdf}

\section{Epilogue}
\subsection{Contribution}
The paper demonstrates that existing hybrid learning algorithms are sensitive to distribution shifts, even when they only concern the parameters of the expert model. Expert augmentation addresses this issue when the interaction model is identifiable from data and shows hybrid learning may construct more robust predictive models than uninformed machine learning. The main contributions are 1) to provide a simplified description of two hybrid learning algorithms within a common probabilistic modelling framework; 2) to describe a class of out-of-distribution settings for which hybrid learning is relevant; 3) to introduce a simple strategy that enforces robustness in these settings.

When the hybrid model is an auto-encoder, expert augmentation is a simple yet effective strategy to improve the model's performance in unseen scenarios. We did not observe a negative impact of expert augmentation in our experiments. The ML practitioner should know that it is possible to guarantee robustness to specific out-of-distribution scenarios only with an expert model that describes the gap between these scenarios and the training data. This is different from describing the out-of-distribution data themselves as it only requires understanding the sub-part of the process, which concerns a potential distribution shift rather than the complete complexity of the entire generative process.

We believe that hybrid learning can change the way measurement devices work. When engineers design a new measurement device, they first start by modelling how the signal of interest relates to first-principles physical effects for which efficient measurement tools exist, such as temperature, light, or audio. For example, a speed camera sends light at a particular frequency against cars. The reflected light undergoes a frequency shift which can be accurately measured with an appropriate photosensor. Then the device estimates the vehicle's speed with the Doppler effect that relates frequency change and speed to each other. This is only a simplified description; in reality, engineers have developed many strategies to improve the robustness and accuracy of speed cameras. They use multiple light frequencies and elaborate signal processing methods and must be calibrated cautiously. It is why these are expensive devices; they rely on costly sensors and necessitate many engineering efforts.

Soon, hybrid learning might unlock the development of new measurement devices. In particular, many practical settings exist for which we know a model of how the signal of interest and the sensor relate to each other. However, in most cases, the model considers an ideal setting which is free from the aggressors that exist in the real world. For example, engineers had either to develop signal processing strategies or elaborate sensors to ensure speed cameras are insensitive to other lights than the one sent by the speed camera itself. Developing better sensors often requires years of research and development in contrast to signal processing, for which hybrid learning may be helpful.

\subsection{Beyond hybrid learning}
\paragraph{Model discovery}
- Symbolic regressions
- Importance of inductive bias

\paragraph{Inference under misspecification}
 - SBI and robust SBI
 - A question is whether we need to define explictly the generative model or not. It can help for sanity check but it forces us to use models that are more complex and may be more sensitive to overfitting.
 - Non-differentiable simulators

\subsection{Conclusion and opportunities}
- hybrid models are suitable for OOD as they allow to pose rigourously the learning probleme and to express generalization in concrete terms and with respect to concrete shifts.

- We could imagine going further and combine models with multiple levels of faithfulness.

- It is not clear how to reach the best results - this is fundamentally problem dependent.

- Faster simulation.

- How do we control the balance between a correct model, a partially correct model and a model that is wrong.
