\thispagestyle{empty}
\section*{}

\vfill

\begin{figure}[h]
  \centering


  \includegraphics[width=.95\textwidth]{figures/chapter02/DALLE_2_Newton.png}
  \caption{\textit{An old painting of Isaac Newton writing the theory of gravity in the language of probability and questioning the role of models in the world.} As seen by $\text{DALL}\cdot\text{E }2$.}
  \label{}
\end{figure}

\vfill

{\centering
\parbox{\textwidth}{%
  \raggedright
  {%\itshape
  % \normal

   If I have seen further, it is by standing on shoulders of giants.\par\bigskip
  }
  \raggedleft{Isaac Newton}\par%
}}

\vfill

\chapter{Hybrid Probabilistic Models}\label{ch:07}

\begin{chapter_outline}

In this chapter we explore deep probabilistic models informed by expert models, hybrid models.
We formalise hybrid learning within the probabilistic modelling framework and demonstrate that hybrid models exhibit greater generalisation capabilities than classical machine learning models.
Hybrid models reduce the misspecification of expert models with a machine learning (ML) component learned from data. We leverage the insight that the expert model is usually valid even outside the training domain to introduce a hybrid data augmentation strategy termed \textit{expert augmentation}. In contrast to many ML algorithms, the performance guarantees of hybrid models trained with expert augmentation are not limited to the training distribution. We validate the practical benefits of augmented hybrid models on a set of controlled experiments and reflect on the broader impact that hybrid learning may have shortly.

\end{chapter_outline}

\section{Prologue}
In this thesis, we have presented various algorithms to help practitioners build models from data. The previous chapter has shown that inductive bias is necessary to learn models from medium or high-dimensional data. Following the growing deployments of ML solutions into the real world~\citep{wehenkel1998automatic} and the related demand for performance guarantees throughout their lifetime~\citep{lwakatare2020large}, the ML research community has gained interest in out-of-distribution robustness~\citep{sehwag2019analyzing, hendrycks2021many}. Machine learning algorithms are not anymore judged only on their ability to produce faithful models inside the training distribution but also on the behaviour of these models in out-of-distributions scenarios.

Although the concept of out-of-distribution robustness seems appealing, it does not clearly say what we seek. To use this concept rigorously, we argue that we shall first answer the following related questions: $\bullet$~\textit{What is in-distribution?} $\bullet$~\textit{What is out-of-distribution?}  $\bullet$~\textit{What is the measure of robustness?} Refusing to answer one of these questions will inevitably lead to an ill-posed ML problem. It is essential to notice the distinction between out-of-distribution and \textit{not} in-distribution. In practice, we might need to restrain ourselves to out-of-distribution settings that correspond to a well-defined subset of what is not in distribution. Finally, we shall be able to express robustness with a quantitative metric.

Hybrid models are the ones that explicitly combine expert models with a machine learning component. They constitute an excellent alternative to purely data-driven solutions and expert models that rely on assumptions often violated in practice. We expect that hybrid models require less data to achieve performance on par with ML models. They may also exhibit better interpretability. In addition, we argue that hybrid models are particularly well suited to work within the context of out-of-distribution robustness. Indeed, the expert model often depends on a low-dimensional set of parameters for which we can provide an informed definition of in-distribution and out-of-distribution.

In line with this argument, we propose an augmentation strategy based on the expert model that enforces a well-defined notion of robustness for a specific out-of-distribution scenario. We show that existing hybrid learning algorithms may learn effective representation but require an additional augmentation step to exhibit robustness. This chapter demonstrates that informed machine learning may achieve results that are out of reach for uninformed solutions. It also shows, once again, that combining various models may be beneficial.

% Nevertheless, recent results in image-to-text have defied this statement by combining large amounts of data with the effective inductive bias of modern deep learning techniques.
% - Limitation of classical machine learning algorithms is to be limited to the data they see. Inductive bias help going a bit beyond but is usually a weak form of prior knowledge that does not help much. In some setting it feels inneficient to try to learn everything from data. This is especially true in domains for which physics playa an important role.
%
% - A particular problem is the one of OOD data. That is if one of the marginal distribution is different. Explain why this may be a problem for general probabilistic models. In this case we need more than inductive bias. We need to understand what is the impact of distribution shift and to be able to make the model performance insensitive to it.
%
% - In the context of this thesis we have seen how relevant it can be to combine models. Now we push this even further by combining physics equations to depends on few parameters that provide a good high level explanation of  phenomenon but misses some lower effects and thus are innefective at doing a great prediction job in some setting. We combine with machine learning models to improve they predicition capabilities. We finally show that such hybrid models exhibits strong generalization performance outside from the training data with respects to shift that can be modeled accuratly by the physical equation.

\section{Robust Hybrid Learning With Expert Augmentation}

\subsection{Author contributions}
I co-authored this paper during an internship at Apple within the Health AI team led by Guillermo Sapiro. Hsu Hiang initially explored the idea of combining expert models with machine learning under the advisory of Jens Behrmann and J{\"o}rn-Henrik Jacobsen. I took over Hsu's work and, together with Jens and J{\"o}rn, we explored a probabilistic formulation of hybrid modelling and out-of-distribution robustness. We designed the experiments together, and I wrote the code corresponding to the two hybrid modelling frameworks (APHYNITY and the hybrid-VAE) used in this project. Gilles helped write the paper and design additional experiments to check the robustness of the expert augmentation in different settings. Guillermo gave feedback on the manuscript. Finally, Gilles, Jens, and J{\"o}rn gave feedback on the manuscript and helped me improve its writing.

\subsection{Reading tips}
The methods explored in the paper are specific to hybrid learning and have not been described in the background. Thus we encourage the reader to carefuly review the complete paper.

\includepdf[pages=-]{papers/Hybrid_learning_preprint.pdf}

\section{Epilogue}
\subsection{Contribution}
The paper demonstrates that existing hybrid learning algorithms are sensitive to distribution shifts, even when they only concern the parameters of the expert model. Expert augmentation addresses this issue when the interaction model is identifiable from data and shows hybrid learning may construct more robust predictive models than uninformed machine learning. The main contributions are i) to provide a simplified description of two hybrid learning algorithms within a common probabilistic modelling framework; ii) to describe a class of out-of-distribution settings for which hybrid learning is relevant; iii) to introduce a simple strategy that enforces robustness in these settings.

When the hybrid model is an auto-encoder, expert augmentation is a simple yet effective strategy to improve the model's performance in unseen scenarios. We did not observe a negative impact of expert augmentation in our experiments. ML practitioners should be aware that guaranteeing robustness to specific out-of-distribution scenarios is feasible. It only requires an expert model that describes the gap between these scenarios and the training data. In contrast to classical augmentation strategies which describe the out-of-distribution data themselves, Augmented hybrid models only require understanding a sub-part of the process related to the distribution shift.

We believe that hybrid learning can change the way measurement devices work. When engineers design a new measurement device, they first start by modelling how the signal of interest relates to first-principles physical effects for which efficient measurement tools exist, such as temperature, light, or sound.

For instance, a speed camera sends light at a given frequency against cars. The reflected light undergoes a frequency shift which can be accurately measured with an appropriate photosensor. Then the device estimates the vehicle's speed with the Doppler effect that relates frequency change and speed to each other. This is only a simplified description; in reality, engineers have developed many strategies to improve the robustness and accuracy of speed cameras. They use multiple light frequencies and elaborate signal processing methods and the camera must be calibrated cautiously. This is what makes these devices expensive; they rely on costly sensors and engineering efforts.

Soon, hybrid learning might unlock the development of new measurement devices at a reduced cost. Many practical settings exist for which we know a model of how the signal of interest and the sensor relate to each other. However, in most cases, the model considers an ideal setting which is free from aggressors which exist in the real world. For example, engineers had either to develop signal processing strategies or elaborate sensors to ensure speed cameras are insensitive to other lights than the one sent by the speed camera itself. Developing better sensors often requires years of research and development in contrast to signal processing. We speculate that hybrid learning might help finding better signal processing strategies and could reduce the development costs of new sensors in the future.

\subsection{Beyond hybrid learning}
\paragraph{Symbolic model discovery}
% - Symbolic regr
% For hundread of years, we have described complex phenomenon with simple mathematical formulas and managed to achieve astonishing tasks.
Most modern prediction or measurement tools are still free of machine learning solutions. They lean on a profound understanding of the underlying processes described with simple mathematical formulas. Nevertheless, we cannot deny the increasing impact of machine learning on the world. In some sense, symbolic model discovery~\citep[][SMD]{schmidt2009distilling,kusner2017grammar,sahoo2018learning} reconciles these two observations. It aims at discovering simple mathematical rules that accurately describe data.

Recent SMD techniques~\citep{cranmer2020discovering} first learn a deep probabilistic model from a large amount of data and then fit a simple mathematical formula to the learnt model via classical symbolic regression tools~\citep{schmidt2009distilling}. This two-step strategy benefits from the practical inductive bias of modern deep learning architectures to generalise better than techniques that directly fit a symbolic model to the data. \citet{cranmer2020discovering} demonstrated that this strategy is effective for retrieving non-trivial cosmology and might be relevant for interpreting neural networks and discovering novel physics. In addition to their interpretability, symbolic models usually exhibit better generalisation than the corresponding neural network. Symbolic models typically correspond to simpler models that are less prone to overfitting -- compressing the neural networks into a few equations acts as a powerful regularisation strategy.

We believe that progress in symbolic model discovery might eventually improve hybrid learning algorithms. Applying SMD to extract a short mathematical description of the interaction model might unlock efficient model discovery grounded on the partial understanding of the phenomenon described by the expert model. In some cases, simple formulas would not be expressive enough to describe the gap between the expert model and reality accurately. We imagine a hybrid model of three components:
i) the expert model;
ii) a minimal length formula describing the most important part of the misspecification;
iii) a deep learning model accounting for the remaining gap.

\paragraph{Inference under misspecification}
The hybrid learning algorithms considered in the paper jointly build an encoder network that identifies the parameters of the expert model and an interaction model that accounts for the misspecification of the expert model. After training, we can apply the encoder to unseen data and obtain an estimation of the expert model's parameters. However, it is unclear whether we should believe in such estimators as the hybrid model might modify the meaning of the expert parameters.

Another problem of the hybrid model's encoders is their incapacity to reflect uncertainty faithfully. Simulation-based inference~\citep[][SBI]{cranmer2020frontier} methods do not acknowledge model misspecifications but provide an accurate estimation of the uncertainty of the parameters' value~\citep{Cannon2022InvestigatingTI}. These methods provide efficient algorithmic solutions to perform inference over the parameters of a simulator, even when it is not differentiable. However, the guarantees of classical SBI collapse if the model is misspecified. Recently, inspired by robust Bayesian inference~\citep{cherief2020mmd,knoblauch2019generalized}, robust SBI~\citep{dellaporta2022robust} has acknowledged that even complex simulators are misspecified. Still, we believe that robust SBI may be inefficient, and machine learning techniques inspired by hybrid learning might lead to efficient solutions for robust SBI. We believe that the inductive bias of machine learning models combined with a large amount of data should outperform existing robust SBI techniques that rely on classical statistical arguments. One challenge to achieving this is to develop solutions compatible with non-differentiable simulators and efficiently benefit from a large amount of unlabeled data.

\subsection{Conclusion and opportunities}
We have observed that hybrid models have robustness properties that are out of reach for purely data-driven machine learning models. In contrast to the classical ML setting, hybrid learning methods embed more than an inductive bias. They start from the assumption that a large part of the phenomenon observed can be described with an expert model. We formulate and achieve a notion of robustness that concerns the effects encoded by the expert model; our simple yet effective augmentation strategy unlocks this robustness in existing hybrid models. Our experiments show the benefit of the augmentation both concerning the parameter identification quality and the hybrid model's predictive accuracy.

There is arguably a significant potential for future development and applications for hybrid models. For example, we foresee the application of hybrid learning to accelerate simulations by augmenting a simplified expert model with a fast machine learning component to close the gap between the fast and inaccurate expert model and the expensive and precise simulator.
%It could be possible to transform complex simulators into fast differentiable programs prescribed into hybrid models.

We must also acknowledge that model discovery is a challenging problem and inevitably requires some level of causal intervention. We should be careful about when and how we use hybrid learning. In particular, some information about the expert model misspecification and how it relates to the training data is necessary to apply hybrid learning successfully. For instance, the information that some data points correspond to the same physical parameters might suffice. In this case, the inference network should predict parameter estimates consistent within groups of attributes. We argue that the inductive bias of the interaction model is crucial when data is scarce.

This work has only explored existing solutions that focus on differentiable expert models. Both methods considered, APHYNITY and the hybrid-VAE, provide a generic solution that does not require supervision. In the future, hybrid learning algorithms should be compatible with other settings. For example, the differentiability requirement still limits the range of direct applications of hybrid learning. Moreover, the genericity of existing algorithms might prevent their data efficiency in settings where we have some information about the expert parameters of the training data. There it would make sense to formulate hybrid learning as a semi-supervised machine learning problem rather than an unsupervised one to benefit from the additional structure in the data.

At a higher level, this chapter has demonstrated another benefit of combining probabilistic models: generalisation capabilities that defy results from a naive interpretation of learning theory. Over the past few years, expert models have shifted from black-box languages (e.g., C++ or Matlab) to differentiable probabilistic frameworks. In this context, we anticipate excellent opportunities for hybrid learning. This transition shall streamline interactions between deep probabilistic and expert models. This paradigm motivates further theoretical and practical developments in hybrid learning. For instance, developing new algorithms and the corresponding conditions under which the hybrid model outperforms data-driven solutions is a relevant goal to help practitioners solve real-world problems with hybrid models.
%In the context of hybrid learning, we combine a very flexible deep probabilistic model with an elementary model derived from first-principles physics and motivated by domain expertise. In the future, we hope hybrid learning will be developed further and allow a better understanding of its abilities and limitations.
