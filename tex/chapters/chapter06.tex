
\begin{figure}[h]
  \centering

  % \caption{An old painting of Isaac Newton writing the theory of gravity in the language of probability and questioning the role of models in the world. Made by $\text{DALL}\cdot\text{E }2$.}
  \includegraphics[width=.95\textwidth]{figures/chapter02/DALLE_2_Newton.png}
  \label{}
\end{figure}

\vfill

{
\textit{\justify
   I prefer dangerous freedom over peaceful slavery.}

  \par\bigskip
  \raggedleft\MakeUppercase{Thomas Jefferson}
  \par%
}

\chapter{Structured Density Estimation}\label{ch:06}

\begin{chapter_outline}
  In this chapter, we aim to go beyond uninformed probabilistic modelling. We now focus on \textit{informed} probabilistic model.
  For this purpose, we introduce the graphical normalizing flow. This new normalizing flow embeds explicit inductive bias in the form of prescribed independencies. This transformation unifies Bayesian networks, coupling and autoregressive layers altogether. Graphical normalizing flows embed domain knowledge in the form of independencies while preserving the interpretability of Bayesian networks and the representation capacity of normalizing flows. In addition to the straightforward embedding of prescribed independencies, graphical conditioners can also discover relevant independence from data only. We analyse the effect of l1-penalization on the recovered probabilistic model and show that it improves the generalisation of normalizing flows.
  %Finally, we also observe that graphical conditioners are competitive with state-of-the-art density estimators.
\end{chapter_outline}

\section{Prologue}
% Replace by something like: In this chapter, we argue that the universality of the UMNN-MAF introduced in the last chapter is a weakness if it does not come with good inductive bias. AKA MAKE IT DIRECT.
In \Cref{ch:05}, we have introduced a universal approximator of continuous density functions called UMNN-MAF. Universality is a desirable property as it implies convergence of the MLE toward the correct model as the number of training points grows. However, in many practical settings, the number of points does not grow sufficiently fast to discriminate between all possible models. This is the curse of dimensionality, and universality becomes an issue rather than an solution.

One potential solution is to take a Bayesian approach and bias the learning toward more plausible models. However, we need to express a prior distribution over the considered class of models to do this. Unfortunately, distributions over complex functions, such as normalizing flows, are challenging to represent. As an alternative, we can exclude models that are irrelevant for describing the phenomenon of interest. For instance, we often make (conditional) independence assumptions when building complex models. These independencies lead to a simplified factorisation of the modelled distribution.
%There, we can learn a probabilistic model, such as a normalizing flow, for each factor and potentially better results than if we learn a unique model that does not embed independence assumptions.

While the first solution is generic, it is also challenging to implement. In contrast, humans are reasonably good at drawing independence assumptions between small pieces of a larger system. We can use Bayesian networks to encode these independencies and understand the big picture produced by these low-level assumptions. The paper featured in this chapter introduces normalizing flows as a parameterisation of the conditional distributions of Bayesian networks for continuous variables. Similarly to the autoregressive or coupling layers that lift invertible transformations from scalar to vector, the structure of any Bayesian network is a valid transformer for normalizing flows. This unified framework reveals the potential of combining prescribed independencies and expressive bijective transformations together.

Unifying Bayesian networks and normalizing flows allows years of research from each domain to benefit the other. For example, recent advances in topology discovery~\citep{zheng2018dags} allows us to introduce a new class of probabilistic models where both the conditional densities and the distribution factorisation are trainable components. This class of models is a universal density approximator provided the appropriate parameterisation. However, in contrast to UMNN-MAF, graphical normalizing flows with learnable structure can be elegantly regularised by penalising the absence of independence. In addition, the recovered structure provides interesting insights on independence properties observed in the data and hypothesised by the learnt model.

This contribution is again about the interplay between seemingly distinct classes of probabilistic models. We show that unifying frameworks can create new models with unique properties. In this case, we gain interpretability, a new inductive bias for normalizing flows, and a unified vision of coupling and autoregressive layers that were historically seen as separate classes of models. This contribution is also well aligned with the notion that building effective models requires the correct assumptions. Indeed, in contrast to classical normalizing flows, our model naturally digests prescribed knowledge we may have about the distribution we aim to learn.


\section{The paper: Graphical Normalizing Flows}
\subsection{Author contributions}
Gilles Louppe and I co-authored the paper. Gilles helped me throughout the project to shape the research idea. He also provided substantial help in writing the paper. I developed the connections between Bayesian networks and normalizing flows and the theory to combine graphical normalizing flows with the NOTEARS algorithm for topology discovery. I also wrote the code for all experiments.

\subsection{Reading tips}
The reader should be able to skip section~3 as it describes the basics of normalizing flows and Bayesian network which were already described in the background.

\includepdf[pages=-]{papers/GNF_AISTATS.pdf}

\section{Epilogue}

\subsection{Inductive bias in normalizing flows.}
\begin{figure}
  \centering
  \includegraphics[width=1.\textwidth]{figures/chapter06/Lipschtizness_complexity.pdf}
  \caption{Evolution of the Lipschitz constant of a normalizing flow's log-likelihood along training with the corresponding learning and testing log-likelihood. The training and test sets are composed of $100$ iid samples from a mixture of two Gaussian distributions. We reproduce the training $20$ times and plot the corresponding mean signals. The shaded area represents one standard deviation. As training continues overfitting, the gap between training and testing performance increases with the Lipschitz constant of the flow's log-likelihood.}
  \label{fig:flow_Lipschtizness}
\end{figure}
The Lipschitz constant can be a good summary of the continuous machine learning models' complexity~\citep{virmaux2018lipschitz, weng2018evaluating, bartlett2017spectrally}. Hence we may prevent overfitting by choosing the model with the smallest Lipschitz constant between many fitting equally well the train set~\citep{von2004distance}. We usually control the Lipschitz constant of the model only implicitly, e.g. by penalising the norm of the weights~\citep{krogh1991simple} or adding stochasticity in the learning algorithm~\citep{smith2021origin, bottou2012stochastic}. However, such strategies turn inefficient when the loss function favours models with large Lipschitz constants.

As shown in \Cref{fig:flow_Lipschtizness}, the Lipschitz constant of normalizing flows and overfitting are correlated. Indeed, we optimise the likelihood of the NF, which is directly related to the Lipschitz constant of the modelled density. The density is a function of its first-order derivative with respect to the input -- the Lipshitz constant bounds the likelihood and the highest density peak. The Lipschitz constant can quickly explode for small training sets. Indeed, expressive models may discover spurious relationships between variables. These spurious relationships are complicated and lead to large Lipschitz constants. Thus by enforcing independencies, prescribed or discovered in the data, graphical normalizing flows may avoid these traps and overfit less. Meanwhile, the relationships discover by graphical normalizing flows are simpler and generalise better.

% - As any machine learning model - Strong Smoothness - that is Lipshitz continuity - is something we aim usually. Discuss it can be hard to achieve for degenrate cases such as deterministic relationship between variables which reduce the dimensionnality of the support - provide an example. In this case it produces an infinite Jacobian and the learnt model as seemingly an infinite likelihood. Explain why this artefact happen. The problem is that for finite number of samples we can more easily discover a spurious deterministic relationship between variables. This relationship would be complex but the model would be happy to find it as it would maximize the likelihood. In contrast, if we enforce a certain level of independence  then we will ignore such complex transformation andf we will tend to produce smoothness as a by product. Learning independence would naturally get closer to simpler solution with respect to the conditional densities and thus would prevent complex relationship that are incompatible with smoothness.
There may also exist a genuine deterministic relationship between variables which implies that the data lie on a manifold. For instance, let us consider predicting the distribution of birds on the world atlas. We must choose between a distribution over 3D real numbers or 2D longitudinal and latitudinal coordinates that encode the birds' position. On the one hand, the 3D parameterisation contains a non-spurious deterministic relationship which is the equation of the surface of the atlas. On the other hand, the latter formalisation does not operate with real numbers, nor in an euclidean space. In this context, graphical normalizing flows cannot help much. However, there is a rich litterature~\citep{kohler2021smooth, mathieu2020riemannian, gemici2016normalizing, kalatzis2021multi, rezende2020normalizing} about normalizing flows on manifolds, which can help prevent numerical instabilities and also provide a powerful inductive bias to ease the learning task.

Finally, another way to improve the inductive bias of normalizing flows is to design invertible layers that mimic effective non-invertible architectures. This translation is not always straightforward, but it can be worth the time spent. Glow~\citep{kingma_glow_2018} is a perfect example; they borrow ideas from convolutions, pooling, and hierarchical VAEs to achieve state-of-the-art image synthesis at the time.


% \paragraph{The relationship between causal and independence discovery.}


\subsection{Scientific impact}
The graphical conditioner unifies autoregressive and coupling layers under a unique architecture with a non-singular binary matrix that controls the topology. This unification can ease the search for the best architecture and simplify the code behind different types of normalizing flows. As discussed, the main feature of graphical normalizing flows is to provide an explicit treatment of independencies. Not only does this offers more interpretability, but it is also a new inductive bias that can help avoid overfitting. In addition, 1-step graphical normalizing flows achieve performance on par with multiple steps flows but have a reduced complexity for generating samples. Graphical normalizing flows also emphasise that powerful models rely on strong assumptions and are not often purely data-driven.

According to Google Scholar, our paper has received $17$ citations between its publication at AISTATS in April 2021 and August 2022. Among these, we notice the work from \citet{mouton2022graphical} that combine residual networks with graphical normalizing flows to improve the stability and efficiency of computing the inverse transformation. In \citet{mouton2022siren}, the same authors exploit the additional structure of graphical normalizing to improve VAEs. Another line of work proposed by \citet{balgi2022personalized} is using graphical normalizing flows to discover causal structures. They show that graphical NFs may find relevant relationships and are particularly well suited for counterfactual inference.

\subsection{Conclusion and opportunities}
We have introduced a new type of normalizing flow that combines Bayesian networks with neural networks. This architecture emphasises the importance of making assumptions when learning probabilistic models and eases the handling of independencies within the Normalizing flow framework. As a nice byproduct, graphical normalizing flows unify autoregressive and coupling transformers under a unique layer. In addition to being an expressive graphical and deep probabilistic model, subsequent work has also demonstrated that graphical normalizing flows can be equipped with a causal flag in specific contexts.

Graphical normalizing flows also have substantial limitations. One of them is that they lose the Bayesian network interpretation as soon as the number of NF steps exceeds one. This restriction is inconsequential as one-step graphical flows are universal density approximators; there is no substantial motivation for stacking multiple steps. When independence assumptions live, we think that graphical normalizing flows should be tested and might better represent the phenomenon of interest than other types of flows.

A critical limitation of normalizing flows exists when there is no prescribed independence, and we aim to discover them from data. Although graphical NFs may learn relevant Bayesian network topologies and generalise better than alternative flow architectures, the corresponding optimisation problem is hard to solve. An exciting line of future work would be to work out the numerical stability of the Lagrangian optimisation, as proposed by \citet{ng2022convergence}. Another issue of our method happens during optimisation when the topology does not correspond to a directed acyclic graph. Hence, the corresponding normalizing flow is not invertible, which impedes the inverse theorem from providing an exact likelihood. In the future, it would be worth exploring whether sampling sub-graphs that are acyclic improves the overall learning algorithm.

A complete Bayesian treatment of normalizing flows is out-of-reach. They rely on neural networks, and Bayesian neural networks~\citep{mackay1995bayesian} are still an active research area. It is unclear whether one day we will be able to express effectively prior and posterior distributions over neural networks. Less ambitious but potentially worthy, expressing distributions over (conditional) independence might be an alternative that could provide valuable insights into the learnt models. In particular, we believe that graphical normalizing flows combined with an efficient sampling strategy that builds a valid Bayesian network structure from the posterior distribution over (conditional) independence might become an effective modelling strategy.

To conclude, we have once again demonstrated the relevance of drawing connections between distinct classes of models. Here, we have argued that Bayesian networks and normalizing flows share in common the factorisation of a joint density via the Bayes' rule. This new perspective enables exploiting topology discovery algorithms within normalizing to improve the expressivity of their inductive bias. We have demonstrated the relevance of acknowledging independence assumptions when possible and discovering them to avoid overfitting and learn better models.

% Limitations regarding the intractability of optimizing structure. Our optimization problem is very hard to solve. Further work on the optimization landscape is needed. Limitations regarding the point estimate we provide of the independence in the end whereas - complete posterior is better and might help smoothing the loss. For causal discovery this is very limiting as we might have many graphs with alsmot the same independence but that corresponds to very different causal models. Proiding the complete distribution over DAG would be awesome for causal discovery.
%
% It has not been used to much by users of flows. Two reasons. independence is too strong. Sometimes not known. Here again starting with a prior instead of a complete matrix or DAG would help. But also it is not clear how we could naturally enforce weak interactions as softer constraint.
%
% It is also nicely showing the interest of embedding expert knowledge when possible. When not, the unification of BNet with flows allow to exploit the algorithms of structure learning for NFs. It allows more interpretability.
% But also more work is requireed to make these algorithms simpler to use and scale to higher dimensions. Also independence is not always the best way to express/enforce desirable/expected properties of the probabilistic model.
%
% Alternative ways of learning jointly the distribution and topology.
