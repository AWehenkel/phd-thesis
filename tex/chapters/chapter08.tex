\chapter{Conclusion}\label{ch:08}


\section{Summary}
- Uninformed vs informed models
- Combining models is nice.
- All the advice we should remember flows.
  1) Do not use to many steps without a good reasons, it does not help expressivity.
  2) If possible use expressive 1D transformation such as monotonic ones.
  3) But also bias the learning toward reasonable models - embed as much domain knowledge as you can.


\section{The future of deep probabilistic modelling}
\subsection{Computing complexity}
- training
- evaluation

\subsection{Potential applications}

\subsection{Informed models}
- Automatic model discovery within simulators
- Use of language models to express hypothesis more easily
- SBI and data oriented models

---- Random thoughts
- Bayesian treatments of deep probabilistic models
-
